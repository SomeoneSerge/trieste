{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe4322ce",
   "metadata": {},
   "source": [
    "# Building models with configuration dictionaries\n",
    "\n",
    "If you are an expert user of Trieste and some modelling library, GPflow for example, then building models via a configuration dictionary might be a useful alternative to working with model and optimizer wrappers. Here we provide an overview of how to use configuration dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "032f4650",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T10:38:02.994303Z",
     "iopub.status.busy": "2021-12-29T10:38:02.993745Z",
     "iopub.status.idle": "2021-12-29T10:38:05.165716Z",
     "shell.execute_reply": "2021-12-29T10:38:05.166259Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import gpflow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "import trieste\n",
    "from trieste.objectives import (\n",
    "    BRANIN_SEARCH_SPACE,\n",
    "    SCALED_BRANIN_MINIMUM,\n",
    "    scaled_branin,\n",
    ")\n",
    "from trieste.objectives.utils import mk_observer\n",
    "from trieste.space import Box\n",
    "\n",
    "np.random.seed(1793)\n",
    "tf.random.set_seed(1793)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e02b1d",
   "metadata": {},
   "source": [
    "## Finding a minimum of the Branin function\n",
    "\n",
    "In this example, as in many other tutorials, we look to find the minimum value of the familiar two-dimensional Branin function over the hypercube $[0, 1]^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "527931b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T10:38:05.171281Z",
     "iopub.status.busy": "2021-12-29T10:38:05.170755Z",
     "iopub.status.idle": "2021-12-29T10:38:05.176079Z",
     "shell.execute_reply": "2021-12-29T10:38:05.175663Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# convert the objective function to a single-output observer\n",
    "observer = trieste.objectives.utils.mk_observer(scaled_branin)\n",
    "\n",
    "# Sample the observer over the search space\n",
    "num_initial_points = 5\n",
    "search_space = BRANIN_SEARCH_SPACE\n",
    "initial_query_points = search_space.sample_sobol(num_initial_points)\n",
    "initial_data = observer(initial_query_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0168f38d",
   "metadata": {},
   "source": [
    "## Standard way of setting up a model of the objective function\n",
    "\n",
    "The Bayesian optimization procedure estimates the next best points to query by using a probabilistic model of the objective. We'll use Gaussian Process (GP) regression in this tutorial, as provided by GPflow.\n",
    "\n",
    "The GPflow models cannot be used directly in our Bayesian optimization routines, only through a valid model wrapper. Trieste has wrappers that support several popular models. For instance, `GPR` and `SGPR` models from GPflow have to be used with the `GaussianProcessRegression` wrapper. These wrappers standardise outputs from all models, deal with preparation of the data and implement additional methods needed for Bayesian optimization.\n",
    "\n",
    "Typical process of setting up a valid model would go as follow.  We first set up a GPR model, using some initial data to set some parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "239696ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T10:38:05.183251Z",
     "iopub.status.busy": "2021-12-29T10:38:05.180905Z",
     "iopub.status.idle": "2021-12-29T10:38:05.200744Z",
     "shell.execute_reply": "2021-12-29T10:38:05.201431Z"
    }
   },
   "outputs": [],
   "source": [
    "from gpflow.models import GPR\n",
    "\n",
    "from trieste.models.gpflow import GaussianProcessRegression\n",
    "from trieste.models.optimizer import Optimizer\n",
    "\n",
    "\n",
    "def build_model(data):\n",
    "    variance = tf.math.reduce_variance(data.observations)\n",
    "    kernel = gpflow.kernels.Matern52(variance=variance, lengthscales=[0.2, 0.2])\n",
    "    gpr = gpflow.models.GPR(data.astuple(), kernel, noise_variance=1e-5)\n",
    "    return gpr\n",
    "\n",
    "\n",
    "gpflow_model = build_model(initial_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da88ec0",
   "metadata": {},
   "source": [
    "Usually constructing a GPflow model would be enough, as it is the only required argument for the model wrappers. Wrappers have other arguments â€” an `optimizer` argument as a rule and potentially some additional model arguments (for example, `num_kernel_samples` in `GaussianProcessRegression`). These arguments are set to sensible defaults and hence typically we can simplify the model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d7846fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T10:38:05.205638Z",
     "iopub.status.busy": "2021-12-29T10:38:05.204778Z",
     "iopub.status.idle": "2021-12-29T10:38:05.209252Z",
     "shell.execute_reply": "2021-12-29T10:38:05.208565Z"
    }
   },
   "outputs": [],
   "source": [
    "model = GaussianProcessRegression(gpflow_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2146fb",
   "metadata": {},
   "source": [
    "However, as expert users, we might want to customize the optimizer for the model and set some arguments that we want to pass to it. We need to use Trieste's optimizer wrappers for that; here `Optimizer` would be the suitable wrapper. We'll optimize our model with GPflow's Scipy optimizer and pass some custom parameters to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33648048",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T10:38:05.213186Z",
     "iopub.status.busy": "2021-12-29T10:38:05.212348Z",
     "iopub.status.idle": "2021-12-29T10:38:05.216129Z",
     "shell.execute_reply": "2021-12-29T10:38:05.215697Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = Optimizer(\n",
    "    optimizer=gpflow.optimizers.Scipy(),\n",
    "    minimize_args={\"options\": dict(maxiter=100)},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb4f419",
   "metadata": {},
   "source": [
    "Finally we build a valid model that can be used with `BayesianOptimizer`. For the `GPR` model we need to use the `GaussianProcessRegression` wrapper. We also set a wrapper specific parameter for initialising the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a9dd4a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T10:38:05.219968Z",
     "iopub.status.busy": "2021-12-29T10:38:05.219111Z",
     "iopub.status.idle": "2021-12-29T10:38:05.222644Z",
     "shell.execute_reply": "2021-12-29T10:38:05.222212Z"
    }
   },
   "outputs": [],
   "source": [
    "model = GaussianProcessRegression(\n",
    "    gpflow_model, optimizer=optimizer, num_kernel_samples=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3af33ee",
   "metadata": {},
   "source": [
    "We can now run the Bayesian optimization loop by defining a `BayesianOptimizer` and calling its `optimize` method. We are not interested in results here, but for the sake of completeness, lets run the Bayesian optimization as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e9f6be0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T10:38:05.227306Z",
     "iopub.status.busy": "2021-12-29T10:38:05.226492Z",
     "iopub.status.idle": "2021-12-29T10:38:10.407697Z",
     "shell.execute_reply": "2021-12-29T10:38:10.407237Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization failed at step 1, encountered error with traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/trieste/bayesian_optimizer.py\", line 395, in optimize\n",
      "    model.optimize(dataset)\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/trieste/models/gpflow/models.py\", line 240, in optimize\n",
      "    self.optimizer.optimize(self.model, dataset)\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/trieste/models/optimizer.py\", line 95, in optimize\n",
      "    return self.optimizer.minimize(loss_fn, variables, **self.minimize_args)\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/gpflow/optimizers/scipy.py\", line 91, in minimize\n",
      "    func, initial_params, jac=True, method=method, **scipy_kwargs\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/scipy/optimize/_minimize.py\", line 624, in minimize\n",
      "    callback=callback, **options)\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\", line 267, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\", line 233, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\", line 134, in fun_wrapped\n",
      "    return fun(np.copy(x), *args)\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/scipy/optimize/optimize.py\", line 74, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/scipy/optimize/optimize.py\", line 68, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/gpflow/optimizers/scipy.py\", line 113, in _eval\n",
      "    loss, grad = _tf_eval(tf.convert_to_tensor(x))\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 828, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 862, in _call\n",
      "    results = self._stateful_fn(*args, **kwds)\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2943, in __call__\n",
      "    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1919, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 560, in call\n",
      "    ctx=ctx)\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError:  Input matrix is not invertible.\n",
      "\t [[node gradient_tape/triangular_solve/MatrixTriangularSolve (defined at opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/gpflow/optimizers/scipy.py:173) ]] [Op:__inference__tf_eval_14396]\n",
      "\n",
      "Errors may have originated from an input operation.\n",
      "Input Source operations connected to node gradient_tape/triangular_solve/MatrixTriangularSolve:\n",
      " Cholesky (defined at opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/gpflow/models/gpr.py:87)\n",
      "\n",
      "Function call stack:\n",
      "_tf_eval\n",
      "\n",
      "\n",
      "Terminating optimization and returning the optimization history. You may be able to use the history to restart the process from a previous successful optimization step.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bo = trieste.bayesian_optimizer.BayesianOptimizer(observer, search_space)\n",
    "result = bo.optimize(2, initial_data, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f926957",
   "metadata": {},
   "source": [
    "## Using configuration dictionaries\n",
    "\n",
    "Instead of working directly with model and optimizer wrappers, after you know them sufficiently well, you can skip them by using configuration dictionary. It consists of a dictionary with same four arguments that can be passed to any model wrapper: `model`, `model_args`, `optimizer` and `optimizer_args`.\n",
    "\n",
    "In the background Trieste combines the `optimizer` and `optimizer_args` to build an optimizer wrapper and then combines the `model`, `model_args` and optimizer wrapper to build a model using the appropriate model wrapper.\n",
    "\n",
    "Let's see this in action. We will re-use the `GPR` model we have created above and use the same additional arguments. As you can see, you retain all the flexibility but can skip working with the interfaces if you know them well already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "978ac1f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T10:38:10.412581Z",
     "iopub.status.busy": "2021-12-29T10:38:10.412088Z",
     "iopub.status.idle": "2021-12-29T10:38:10.415765Z",
     "shell.execute_reply": "2021-12-29T10:38:10.415284Z"
    }
   },
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"model\": gpflow_model,\n",
    "    \"model_args\": {\n",
    "        \"num_kernel_samples\": 100,\n",
    "    },\n",
    "    \"optimizer\": gpflow.optimizers.Scipy(),\n",
    "    \"optimizer_args\": {\n",
    "        \"minimize_args\": {\"options\": dict(maxiter=100)},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab315be",
   "metadata": {},
   "source": [
    "Next you simply pass the configuration dictionary to the `optimize` function and `BayesianOptimizer` will sort out which model and optimizer wrapper needs to be used to build a valid model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a5a905a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T10:38:10.420711Z",
     "iopub.status.busy": "2021-12-29T10:38:10.419731Z",
     "iopub.status.idle": "2021-12-29T10:38:10.855444Z",
     "shell.execute_reply": "2021-12-29T10:38:10.857487Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization failed at step 0, encountered error with traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/trieste/bayesian_optimizer.py\", line 371, in optimize\n",
      "    model.optimize(dataset)\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/trieste/models/gpflow/models.py\", line 240, in optimize\n",
      "    self.optimizer.optimize(self.model, dataset)\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/trieste/models/optimizer.py\", line 95, in optimize\n",
      "    return self.optimizer.minimize(loss_fn, variables, **self.minimize_args)\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/gpflow/optimizers/scipy.py\", line 91, in minimize\n",
      "    func, initial_params, jac=True, method=method, **scipy_kwargs\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/scipy/optimize/_minimize.py\", line 624, in minimize\n",
      "    callback=callback, **options)\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\", line 308, in _minimize_lbfgsb\n",
      "    finite_diff_rel_step=finite_diff_rel_step)\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/scipy/optimize/optimize.py\", line 262, in _prepare_scalar_function\n",
      "    finite_diff_rel_step, bounds, epsilon=epsilon)\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\", line 140, in __init__\n",
      "    self._update_fun()\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\", line 233, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\", line 134, in fun_wrapped\n",
      "    return fun(np.copy(x), *args)\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/scipy/optimize/optimize.py\", line 74, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/scipy/optimize/optimize.py\", line 68, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/gpflow/optimizers/scipy.py\", line 113, in _eval\n",
      "    loss, grad = _tf_eval(tf.convert_to_tensor(x))\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 828, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 895, in _call\n",
      "    filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1919, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 560, in call\n",
      "    ctx=ctx)\n",
      "  File \"/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError:  Input matrix is not invertible.\n",
      "\t [[node gradient_tape/triangular_solve/MatrixTriangularSolve (defined at opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/gpflow/optimizers/scipy.py:173) ]] [Op:__inference__tf_eval_15162]\n",
      "\n",
      "Errors may have originated from an input operation.\n",
      "Input Source operations connected to node gradient_tape/triangular_solve/MatrixTriangularSolve:\n",
      " Cholesky (defined at opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/gpflow/models/gpr.py:87)\n",
      "\n",
      "Function call stack:\n",
      "_tf_eval\n",
      "\n",
      "\n",
      "Terminating optimization and returning the optimization history. You may be able to use the history to restart the process from a previous successful optimization step.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bo = trieste.bayesian_optimizer.BayesianOptimizer(observer, search_space)\n",
    "result = bo.optimize(2, initial_data, model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32347438",
   "metadata": {},
   "source": [
    "## Using configuration dictionaries for setting up experiments\n",
    "\n",
    "Another use case is in setting up experiments, where it becomes easier to benchmark Bayesian optimization algorithms. The advantage is that we can easily change the models and set up any argument for them from one experiment to another. We only need to change the object with the experiment specification (`experiment_conditions` below), while the rest of the code for executing experiments can stay the same. Below is an illustration of how could that look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55bbe61b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T10:38:10.866689Z",
     "iopub.status.busy": "2021-12-29T10:38:10.860415Z",
     "iopub.status.idle": "2021-12-29T10:38:29.193243Z",
     "shell.execute_reply": "2021-12-29T10:38:29.192733Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization completed without errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization completed without errors\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "from gpflow.models import SVGP\n",
    "\n",
    "\n",
    "def build_gpr_model(data):\n",
    "    variance = tf.math.reduce_variance(data.observations)\n",
    "    kernel = gpflow.kernels.Matern52(variance=variance, lengthscales=[0.2, 0.2])\n",
    "    model = GPR(data.astuple(), kernel, noise_variance=1e-5)\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_svgp_model(data):\n",
    "    inputs = data.query_points\n",
    "    variance = tf.math.reduce_variance(data.observations)\n",
    "    kernel = gpflow.kernels.Matern52(variance=variance, lengthscales=[0.2, 0.2])\n",
    "    model = SVGP(\n",
    "        kernel, gpflow.likelihoods.Gaussian(), inputs[:2], num_data=len(inputs)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def run_experiment(model_config):\n",
    "    bo = trieste.bayesian_optimizer.BayesianOptimizer(observer, search_space)\n",
    "    result = bo.optimize(2, initial_data, model_config)\n",
    "    return result\n",
    "\n",
    "\n",
    "# configuration shared by all experiments, this is modified by each experiment condition\n",
    "basic_config = {\"model\": build_gpr_model(initial_data)}\n",
    "\n",
    "# here we specify our experiments\n",
    "experiment_conditions = [\n",
    "    {\"model_args\": {\"num_kernel_samples\": 50}},\n",
    "    {\"model\": build_svgp_model(initial_data)},\n",
    "]\n",
    "\n",
    "results = []\n",
    "for exp in experiment_conditions:\n",
    "    model_config = deepcopy(basic_config)\n",
    "    for key in exp:\n",
    "        model_config[key] = exp[key]\n",
    "    results.append(run_experiment(model_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c31ef7f",
   "metadata": {},
   "source": [
    "## Registry of supported models\n",
    "\n",
    "Configuration dictionaries are made possible with the `ModelRegistry` that contains mapping between each model (e.g. GPflow or GPflux) and the corresponding model wrapper and optimizer wrapper. All models that Trieste currently supports are registered there.\n",
    "\n",
    "You can add new models to the registry, in case you have custom models with which you wish to use the configuration dictionaries. Let's see an example of this. We will register the `GPMC` model from GPflow that is currently not supported. You would likely need to create a new model wrapper (and perhaps a new optimizer wrapper as well), but just for the sake of an example we will borrow here an existing `GaussianProcessRegression` wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b2ca35d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T10:38:29.205034Z",
     "iopub.status.busy": "2021-12-29T10:38:29.204518Z",
     "iopub.status.idle": "2021-12-29T10:38:29.209070Z",
     "shell.execute_reply": "2021-12-29T10:38:29.209441Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[gpflow.optimizers.scipy.Scipy,\n",
       " tensorflow.python.keras.optimizer_v2.optimizer_v2.OptimizerV2]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trieste.models import ModelRegistry\n",
    "\n",
    "# adding the GPMC model to the registry\n",
    "ModelRegistry.register_model(gpflow.models.GPMC, GaussianProcessRegression)\n",
    "\n",
    "# check if it has been registered\n",
    "print(gpflow.models.GPMC in ModelRegistry.get_registered_models())\n",
    "\n",
    "# you can use the same command to get a list of all supported models and optimizers\n",
    "list(ModelRegistry.get_registered_models())\n",
    "list(ModelRegistry.get_registered_optimizers())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bdaea6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Note that you can use the same operation to overwrite an existing entry in the registry. For example, if you want to modify the interface used with a registered model and use the modified one instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3b9b3c",
   "metadata": {},
   "source": [
    "## LICENSE\n",
    "\n",
    "[Apache License 2.0](https://github.com/secondmind-labs/trieste/blob/develop/LICENSE)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent"
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
